{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16db7d5f-bc9f-4092-be25-8d9590226f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import ot \n",
    "import os\n",
    "parent_path=%pwd \n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(parent_path)\n",
    "from lib.gromov_test import partial_gromov_v1,partial_gromov_v2, cost_matrix_d,tensor_dot_param,tensor_dot_func,gwgrad_partial,partial_gromov_wasserstein\n",
    "from lib.opt import *\n",
    "from lib.pu import *\n",
    "\n",
    "import numpy as np \n",
    "import numba as nb\n",
    "import warnings\n",
    "import time\n",
    "from ot.backend import get_backend, NumpyBackend\n",
    "from ot.lp import emd\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c07867ec-2b52-4b17-9673-0e67e40f8271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def data_process(name='amazon_surf'):\n",
    "    # open the data file \n",
    "    if name in ['MNIST','EMNIST']:\n",
    "        data_file=torch.load('pu_learning/data/'+name+'.pt')\n",
    "        (X,l)=data_file\n",
    "        classes= None\n",
    "    elif 'surf' in name or 'decaf' in name:        \n",
    "        with open('pu_learning/data/'+name+'_fts.pkl', 'rb') as f:\n",
    "            data_file = pickle.load(f)\n",
    "     \n",
    "        if 'surf' in name:\n",
    "            X0=data_file['features']\n",
    "            l=data_file['labels']\n",
    "            classes=data_file['classes']\n",
    "            pca = PCA(n_components=10, random_state=0)\n",
    "            pca.fit(X0.T)\n",
    "            X = pca.components_.T\n",
    "        elif 'decaf' in name:\n",
    "            X0=data_file['fc8']\n",
    "            l=data_file['labels']\n",
    "            classes=data_file['classes']\n",
    "            pca = PCA(n_components=40, random_state=0)\n",
    "            pca.fit(X0.T)\n",
    "            X = pca.components_.T\n",
    "    return (X,l),classes\n",
    "\n",
    "\n",
    "def MNIST_figure(figure_list,label_list):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(figure_list[i][0], cmap='gray')\n",
    "        plt.title(f\"Label: {label_list[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def normalize_X(X):\n",
    "    div = np.max(X, axis=0) - np.min(X, axis=0)\n",
    "    div[div == 0] = 1 # Avoid division by zero\n",
    "    X = (X - np.min(X, axis=0)) / div\n",
    "    return X\n",
    "    \n",
    "# def convert_data(dataset,name='MNIST',visual=False):\n",
    "#     if name in ['MNIST','EMNIST']:\n",
    "#         X_list,label_list=dataset\n",
    "#             label_list_all.append(label_list)\n",
    "#         embedding_list_all=np.vstack(embedding_list_all)\n",
    "#         label_list_all=np.vstack(label_list_all).reshape(-1).astype(np.int64)\n",
    "#     return embedding_list_all,label_list_all\n",
    "\n",
    "\n",
    "# it is modified version \n",
    "def draw_pu_dataset_scar(dataset_p, dataset_u=None, size_p=10, size_u=20, prior=0.5, p_label=0,seed_nb=None,same_dataset=True):\n",
    "    \"\"\"Draw a Positive and Unlabeled dataset \"at random\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_p: name of the dataset among which the positives are drawn\n",
    "\n",
    "    dataset_u: name of the dataset among which the unlabeled are drawn\n",
    "\n",
    "    size_p: number of points in the positive dataset\n",
    "\n",
    "    size_u: number of points in the unlabeled dataset\n",
    "\n",
    "    prior: percentage of positives on the dataset (s)\n",
    "\n",
    "    seed_nb: seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame of shape (n_p, d_p)\n",
    "        Positive dataset\n",
    "\n",
    "    pandas.DataFrame of shape (n_u, d_u)\n",
    "        Unlabeled dataset\n",
    "\n",
    "    pandas.Series of len (n_u)\n",
    "        labels of the unlabeled dataset\n",
    "    \"\"\"\n",
    "    x, l = dataset_p[0].copy(),dataset_p[1].copy()\n",
    "    A=l==p_label\n",
    "    B=l!=p_label\n",
    "    l[A],l[B]=1,0\n",
    "    x=normalize_X(x)\n",
    "\n",
    "    size_u_p = int(prior * size_u)\n",
    "    size_u_n = size_u - size_u_p\n",
    "    \n",
    "    xp_t = x[l == 1]\n",
    "    tp_t = l[l == 1]\n",
    "\n",
    "    xp, xp_other, _, tp_o = train_test_split(xp_t, tp_t, train_size=size_p,\n",
    "                                             random_state=seed_nb)\n",
    "    #print('xp_other shape',xp_other.shape)\n",
    "    if same_dataset or dataset_u is None:\n",
    "        xup, _, lup, _ = train_test_split(xp_other, tp_o, train_size=size_u_p,\n",
    "                                        random_state=seed_nb)\n",
    "    else:\n",
    "        x, l = dataset_u[0].copy(),dataset_u[1].copy()\n",
    "        x=normalize_X(x)\n",
    "        A=l==p_label\n",
    "        B=l!=p_label\n",
    "        l[A],l[B]=1,0\n",
    "        # x, t = make_data(dataset=dataset_u)\n",
    "        \n",
    "        # div = np.max(x, axis=0) - np.min(x, axis=0)\n",
    "        # div[div == 0] = 1\n",
    "        # x = (x - np.min(x, axis=0)) / div\n",
    "        xp_other = x[l == 1]\n",
    "        tp_o = l[l == 1]\n",
    "        xup, _, lup, _ = train_test_split(xp_other, tp_o,\n",
    "                                        train_size=size_u_p,\n",
    "                                        random_state=seed_nb)\n",
    "\n",
    "    xn_t = x[l == 0]\n",
    "    tn_t = l[l == 0]\n",
    "    xun, _, lun, _ = train_test_split(xn_t, tn_t, train_size=size_u_n,\n",
    "                                    random_state=seed_nb)\n",
    "    \n",
    "    xu = np.concatenate([xup, xun], axis=0)\n",
    "    yu = np.concatenate((np.ones(len(xup)), np.zeros(len(xun)))).astype(np.int64)\n",
    "    yu_2=np.concatenate((lup,lun))\n",
    "    #print(np.linalg.norm(yu-yu_2))\n",
    "    return xp, xu, yu_2\n",
    "\n",
    "def init_pgw_param(C1,C2,r):\n",
    "    n,m=C1.shape[0],C2.shape[0]\n",
    "    q=np.ones(m)/m  \n",
    "    p=np.ones(n)/n*r # make the mass of p to be r\n",
    "    mass=np.min((p.sum(),r))\n",
    "    return p,q,mass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "def gamma_to_l(G,r):\n",
    "    n,m=G.shape\n",
    "    G_2=G.sum(0)\n",
    "    quantile=np.quantile(G_2,1-r)\n",
    "    l_G=np.zeros(m)\n",
    "    l_G[G_2>=quantile]=1\n",
    "    return l_G\n",
    "\n",
    "def init_param_ugw(C1,C2):\n",
    "    n,m=C1.shape[0],C2.shape[0]\n",
    "    n_pos,n_unl=n,m\n",
    "    nb_try=1\n",
    "    mu = (torch.ones([n_pos]) / n_pos).expand(nb_try, -1)\n",
    "    nu = (torch.ones([n_unl]) / n_unl).expand(nb_try, -1)\n",
    "    \n",
    "    grid_eps = [2. ** k for k in range(-9, -8, 1)]\n",
    "    grid_rho = [2. ** k for k in range(-10, -4, 1)]\n",
    "    eps=grid_eps[0]\n",
    "    rho=grid_rho[0]\n",
    "    rho2=grid_rho[0]\n",
    "    Cx=torch.from_numpy(C1).to(torch.float32).reshape((nb_try,n,n))\n",
    "    Cy=torch.from_numpy(C2).to(torch.float32).reshape((nb_try,m,m))\n",
    "    return mu,nu,eps,rho,rho2,Cx,Cy\n",
    "\n",
    "def init_flb_uot(C1,C2):\n",
    "    mu,nu,eps,rho,rho2,Cx,Cy=init_param_ugw(C1,C2)\n",
    "    _, _, init_plan = compute_batch_flb_plan(\n",
    "            mu, Cx, nu, Cy, eps=eps, rho=rho, rho2=rho2,\n",
    "            nits_sinkhorn=50000, tol_sinkhorn=1e-5)\n",
    "    \n",
    "    return init_plan[0].numpy().astype(np.float64)\n",
    "\n",
    "def init_flb_pot(C1,C2,p,q,r,Lambda=30.0):\n",
    "    p,q,mass=init_pgw_param(C1,C2,r)\n",
    "    S1,S2=C1.mean(0),C2.mean(0)\n",
    "    C=cost_matrix(S1,S2)\n",
    "    gamma,_=opt_lp(p,q,C,Lambda=Lambda,numItermax=n*500)\n",
    "    \n",
    "    return gamma\n",
    "\n",
    "def pu_prediction_gw(C1,C2,r=0.2,G0=None,method='pgw',param={'Lambda':30.0}):\n",
    "    C1,C2=C1.astype(np.float64),C2.astype(np.float64)\n",
    "    #C1,C2=cost_matrix_d(X_p,X_p),cost_matrix_d(X_u,X_u)\n",
    "    n,m=C1.shape[0],C2.shape[0]\n",
    "    size_p=int(m*r)\n",
    "    if size_p!=n:\n",
    "        print('# of positives in X_p and X_u are different, we suggest to modify them')\n",
    "    if method=='gw':\n",
    "        p=np.ones(n)/n\n",
    "    if method=='primal_pgw':\n",
    "        p,q,mass=init_pgw_param(C1,C2,r)\n",
    "#       mass=min(r*np.sum(q),np.sum(p)) # this used to avoid numerical issue \n",
    "        C1,C2=C1.astype(np.float64),C2.astype(np.float64)\n",
    "        gamma=partial_gromov_wasserstein(C1,C2,p,q,m=mass,G0=G0,numItermax=n*500,nb_dummies=1,line_search=False)\n",
    "        \n",
    "    if method=='pgw':\n",
    "        Lambda=param['Lambda']\n",
    "        p,q,mass=init_pgw_param(C1,C2,r)\n",
    "        C1,C2=C1.astype(np.float64),C2.astype(np.float64)\n",
    "        gamma,_=partial_gromov_v1(C1,C2,p,q,Lambda=Lambda,G0=G0,numItermax=n*500,nb_dummies=1,line_search=False)\n",
    "    if method=='ugw':\n",
    "        mu,nu,eps,rho,rho2,Cx,Cy=init_param_ugw(C1,C2)\n",
    "        if 'rho' in param:\n",
    "            rho=param['rho']\n",
    "            rho2=rho\n",
    "        if 'eps' in param:\n",
    "            eps=param['eps']\n",
    "        # need to try different rho for better performance\n",
    "#        rho=0.0023 surf A\n",
    "        if type(G0)==np.ndarray:\n",
    "            init_plan=torch.from_numpy(G0).to(torch.float32).reshape((1,n,m))\n",
    "        elif type(G0)==torch.Tensor:\n",
    "            init_plan=G0\n",
    "        gamma = log_batch_ugw_sinkhorn(mu, Cx, nu, Cy, init=init_plan,\n",
    "                                eps=eps, rho=rho, rho2=rho2,\n",
    "                                nits_plan=3000, tol_plan=1e-5,\n",
    "                                nits_sinkhorn=3000, tol_sinkhorn=1e-6)\n",
    "        print('gamma_mass_diff',gamma.sum()-r)\n",
    "        gamma=gamma[0]\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3569c936-73f5-45ce-9e51-e676e47b4f03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 1 is MNIST\n",
      "data 2 is MNIST\n",
      "init method is pot_r\n",
      "accuracy is 1.0\n",
      "time is 0.0068395137786865234\n",
      "accuracy is 1.0\n",
      "time is 0.017379045486450195\n",
      "accuracy is 1.0\n",
      "time is 0.013528823852539062\n",
      "init method is flb_pot\n",
      "accuracy is 0.616\n",
      "time is 0.012134790420532227\n",
      "accuracy is 0.6\n",
      "time is 0.27577686309814453\n",
      "accuracy is 0.6\n",
      "time is 0.12978696823120117\n",
      "data 1 is MNIST\n",
      "data 2 is EMNIST\n",
      "init method is pot_r\n",
      "accuracy is 0.98\n",
      "time is 0.004122734069824219\n",
      "accuracy is 0.996\n",
      "time is 0.05425262451171875\n",
      "accuracy is 0.996\n",
      "time is 0.06846380233764648\n",
      "init method is flb_pot\n",
      "accuracy is 0.608\n",
      "time is 0.00538182258605957\n",
      "accuracy is 0.6\n",
      "time is 0.1330244541168213\n",
      "accuracy is 0.6\n",
      "time is 0.17775559425354004\n",
      "data 1 is EMNIST\n",
      "data 2 is MNIST\n",
      "init method is pot_r\n",
      "accuracy is 0.936\n",
      "time is 0.003538846969604492\n",
      "accuracy is 0.932\n",
      "time is 0.05280351638793945\n",
      "accuracy is 0.932\n",
      "time is 0.06574797630310059\n",
      "init method is flb_pot\n",
      "accuracy is 0.808\n",
      "time is 0.004785776138305664\n",
      "accuracy is 0.908\n",
      "time is 0.05751609802246094\n",
      "accuracy is 0.908\n",
      "time is 0.09339523315429688\n",
      "data 1 is EMNIST\n",
      "data 2 is EMNIST\n",
      "init method is pot_r\n",
      "accuracy is 1.0\n",
      "time is 0.0028717517852783203\n",
      "accuracy is 1.0\n",
      "time is 0.004785060882568359\n",
      "accuracy is 1.0\n",
      "time is 0.005928516387939453\n",
      "init method is flb_pot\n",
      "accuracy is 0.788\n",
      "time is 0.0066776275634765625\n",
      "accuracy is 0.92\n",
      "time is 0.06760501861572266\n",
      "accuracy is 0.92\n",
      "time is 0.06911849975585938\n"
     ]
    }
   ],
   "source": [
    "#nb_dummies=1\n",
    "p_label=0\n",
    "nb_dummies=1\n",
    "name1='MNIST'\n",
    "name2='EMNIST'\n",
    "#name3='webcam_surf'\n",
    "file_name=name1+name2+'.pt' #'surf.pt' #name1+'-'+name2+'.pt'\n",
    "try:\n",
    "    result=torch.load('pu_learning/result/'+filename)\n",
    "except:\n",
    "    result={}\n",
    "n=100\n",
    "r=1/5\n",
    "m=int(n/r)\n",
    "\n",
    "\n",
    "dataset1,_=data_process(name=name1)\n",
    "dataset2,_=data_process(name=name2)\n",
    "\n",
    "dataname_list=[name1,name2]\n",
    "dataset_list=[dataset1,dataset2]\n",
    "init_method_list=['pot_r','flb_pot']\n",
    "method_list=['primal_pgw','pgw'] #\n",
    "for (data1_name,data1) in zip(dataname_list,dataset_list):\n",
    "    for (data2_name,data2) in zip(dataname_list,dataset_list):\n",
    "        print('data 1 is',data1_name)\n",
    "        print('data 2 is',data2_name)\n",
    "        for init_method in init_method_list:\n",
    "            G0 = None\n",
    "            if data1_name==data2_name:\n",
    "                same_dataset=False\n",
    "            else:\n",
    "                same_dataset=True\n",
    "            X_p,X_u,label_u=draw_pu_dataset_scar(data1,data2,p_label=p_label,prior=r,size_p=n, size_u=m,seed_nb=3,same_dataset=same_dataset)\n",
    "            C, C1, C2, mu, nu=compute_cost_matrices(P=X_p, U=X_u, prior=r, nb_dummies=1)\n",
    "            p,q=mu[0:n],nu[0:m]\n",
    "            C1=C1[0:n,0:n]\n",
    "            C2=C2[0:m,0:m]\n",
    "            \n",
    "            \n",
    "            time1=time.time()\n",
    "            if init_method=='pot_r' and C is not None:\n",
    "                G0=ot.emd(mu, nu, C)[:n, :] \n",
    "                #pu_w_emd(mu, nu, C, nb_dummies=nb_dummies)\n",
    "                #G0=G0[0:-nb_dummies,:]\n",
    "            elif init_method=='flb_pot':\n",
    "                G0=init_flb_pot(C1,C2,p,q,r,Lambda=30.0)\n",
    "            elif init_method=='flb_uot':\n",
    "                G0=init_flb_uot(C1,C2)\n",
    "\n",
    "            time2=time.time()\n",
    "            run_time=time2-time1\n",
    "            if G0 is not None:\n",
    "                l_G0=gamma_to_l(G0,r)\n",
    "                acc0=accuracy_score(l_G0,label_u)\n",
    "                result[init_method+'-'+data1_name+'-'+data2_name]={}\n",
    "                result[init_method+'-'+data1_name+'-'+data2_name]['accuracy']=acc0\n",
    "                result[init_method+'-'+data1_name+'-'+data2_name]['time']=run_time\n",
    "                #result[init_method+'-'+data1+'-'+data2]['G0']=G0\n",
    "                print('init method is',init_method)\n",
    "                print('accuracy is',acc0)\n",
    "                print('time is',run_time)    \n",
    "            # if G0 is not None:    \n",
    "                for method in method_list:\n",
    "                    if True: #if init_method+'-'+data1+'-'+data2+'-'+method not in result:\n",
    "                        if method=='ugw':\n",
    "                            param={'None'}\n",
    "                        elif method=='pgw':\n",
    "                            param={'Lambda':20.0}\n",
    "                        else:\n",
    "                            param=None\n",
    "                        time1=time.time()\n",
    "                        G=pu_prediction_gw(C1.copy(),C2.copy(),r=r,G0=G0.copy(),method=method,param=param)\n",
    "                        time2=time.time()\n",
    "                        run_time=time2-time1\n",
    "\n",
    "                        l_G=gamma_to_l(G,r)\n",
    "                        acc=accuracy_score(l_G,label_u)\n",
    "                        result[init_method+'-'+data1_name+'-'+data2_name+'-'+method]={}\n",
    "                        result[init_method+'-'+data1_name+'-'+data2_name+'-'+method]['time']=run_time\n",
    "                        result[init_method+'-'+data1_name+'-'+data2_name+'-'+method]['accuracy']=acc\n",
    "                        \n",
    "                        print('accuracy is',acc)\n",
    "                        print('time is',run_time)\n",
    "                        #torch.save(result,'pu_learning/result/'+file_name)\n",
    "                    \n",
    "# p,q=np.ones(n)*r/n,np.ones(m)/m\n",
    "\n",
    "# l_G0=gamma_to_l(G0,r)\n",
    "# acc_G0=accuracy_score(l_G0,label_u)\n",
    "# print('acc_G0',acc_G0)\n",
    "\n",
    "# if C is not None:\n",
    "#     G0=pu_w_emd(mu, nu, C, nb_dummies=nb_dummies)\n",
    "#     G0=G0[0:-nb_dummies,:]\n",
    "\n",
    "#     l_G0=gamma_to_l(G0,r)\n",
    "#     acc_G0=accuracy_score(l_G0,label_u)\n",
    "#     print('acc_G0',acc_G0)\n",
    "# gamma=pu_prediction_gw(C1,C2,r=r,method='ugw',G0=G0,param={'Lambda':30.0})\n",
    "# l_G=gamma_to_l(gamma,r)\n",
    "# acc=accuracy_score(l_G,label_u)\n",
    "# print('acc',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85797ece-59b0-4351-9a8a-2c3a06907720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
